{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning for Drug – Nanoparticle (DADNP) Systems in HCC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, roc_auc_score,f1_score, recall_score, precision_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import RFECV, VarianceThreshold, SelectKBest, chi2\n",
    "from sklearn.feature_selection import SelectFromModel, SelectPercentile, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define script parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define output variables\n",
    "outVars = ['f(vnj)obs06']\n",
    "\n",
    "# define list of folds\n",
    "foldTypes = [3]\n",
    "\n",
    "# define a label for output files\n",
    "targetName = 'sel'\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  set_weights(y_data, option='balanced'):\n",
    "    \"\"\"Estimate class weights for umbalanced dataset\n",
    "       If ‘balanced’, class weights will be given by n_samples / (n_classes * np.bincount(y)). \n",
    "       If a dictionary is given, keys are classes and values are corresponding class weights. \n",
    "       If None is given, the class weights will be uniform \"\"\"\n",
    "    cw = class_weight.compute_class_weight(option, np.unique(y_data), y_data)\n",
    "    w = {i:j for i,j in zip(np.unique(y_data), cw)}\n",
    "    return w "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function to get data from the datafile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataFromDataset(sFile, OutVar):\n",
    "    # read details file\n",
    "    print('\\n-> Read dataset', sFile)\n",
    "    df = pd.read_csv(sFile, sep='\\t')\n",
    "    print('Shape', df.shape)\n",
    "    print(list(df.columns))\n",
    "\n",
    "    # select X and Y\n",
    "    ds_y = df[OutVar]\n",
    "    ds_X = df.drop(OutVar,axis = 1)\n",
    "    Xdata = ds_X.values # get values of features\n",
    "    Ydata = ds_y.values # get output values\n",
    "\n",
    "    print('Shape X data:', Xdata.shape)\n",
    "    print('Shape Y data:',Ydata.shape)\n",
    "    \n",
    "    # return data for X and Y, feature names as list\n",
    "    return (Xdata, Ydata, list(ds_X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to run all the classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pipeline_OuterCV(Xdata, Ydata, label = 'my', class_weights = {0: 1, 1: 1}, folds = 3, seed = 42, metrics='roc_auc'):\n",
    "    # inputs:\n",
    "    # data for X, Y; a label about data, class_weights, number of folds, seeed\n",
    "    \n",
    "    # default: 10-fold CV, 1:1 class weights (balanced dataset)\n",
    "    priors = [(class_weights[0]/(class_weights[0]+class_weights[1])), (class_weights[1]/(class_weights[0]+class_weights[1]))]\n",
    "    \n",
    "    # define classifiers\n",
    "    names = ['KNN', 'GNB', 'LDA', 'LogR', 'MLP', 'DT', 'RF', 'XGB', 'GB', 'BAG', 'ADA']\n",
    "    classifiers = [KNeighborsClassifier(n_jobs=-1),\n",
    "               GaussianNB(),\n",
    "               LinearDiscriminantAnalysis(solver='svd',priors=priors), # No tiene random_state\n",
    "               LogisticRegression(solver='lbfgs',random_state=seed,class_weight=class_weights,max_iter=20000),\n",
    "               MLPClassifier(hidden_layer_sizes= (5), random_state = seed, max_iter=50000, shuffle=False),\n",
    "               DecisionTreeClassifier(random_state = seed,class_weight=class_weights),\n",
    "               RandomForestClassifier(n_jobs=-1,random_state=seed,class_weight=class_weights),\n",
    "               XGBClassifier(n_jobs=-1,seed=seed,scale_pos_weight= class_weights[0]/class_weights[1]),\n",
    "               GradientBoostingClassifier(random_state=seed),\n",
    "               BaggingClassifier(random_state=seed),\n",
    "               AdaBoostClassifier(random_state = seed)]\n",
    "    \n",
    "    # results dataframe: each column for a classifier\n",
    "    df_res = pd.DataFrame(columns=names)\n",
    "\n",
    "    # build each classifier\n",
    "    print('* Building scaling+feature selection+outer '+str(folds)+'-fold CV for '+str(len(names))+' classifiers:', str(names))\n",
    "    total = time.time()\n",
    "    \n",
    "    # define a fold-CV for all the classifier\n",
    "    outer_cv = StratifiedKFold(n_splits=folds,shuffle=True,random_state=seed)\n",
    "    \n",
    "    for name, clf in zip(names, classifiers):\n",
    "        start = time.time()\n",
    "        \n",
    "        # create pipeline: scaler + classifier\n",
    "        estimators = []\n",
    "        \n",
    "        # SCALER\n",
    "        estimators.append(('Scaler', StandardScaler()))\n",
    "        \n",
    "        # add Classifier\n",
    "        estimators.append(('Classifier', clf)) \n",
    "        \n",
    "        # create pipeline\n",
    "        model = Pipeline(estimators)\n",
    "        \n",
    "        # evaluate pipeline\n",
    "        scores = cross_val_score(model, Xdata, Ydata, cv=outer_cv, scoring=metrics, n_jobs=-1)\n",
    "        \n",
    "        df_res[name] = scores\n",
    "        print('%s, %s_mean=%0.2f, Time:%0.1f mins' % (name, metrics, scores.mean(), (time.time() - start)/60))\n",
    "        \n",
    "    # save results CSV\n",
    "    # -----------------\n",
    "    resFile = './results/'+metrics+'-'+targetName+'_'+str(label)+'_'+str(folds)+'-foldCV.csv'\n",
    "    df_res.to_csv(resFile, index=False)\n",
    "    \n",
    "    print('* Scores saved', resFile)\n",
    "    print('Total time:', (time.time() - total)/60, ' mins')             \n",
    "    \n",
    "    plt.figure()\n",
    "    plt.clf()\n",
    "    \n",
    "    meanpointprops = dict(marker='o', markeredgecolor='green',\n",
    "                          markerfacecolor='green')\n",
    "    \n",
    "    color = dict(boxes='black', whiskers='black', medians='blue', caps='red')\n",
    "    boxplot = df_res.boxplot(column=names,\n",
    "                             meanprops=meanpointprops, meanline=False, showmeans=True,\n",
    "                             color=color,\n",
    "                             whiskerprops = dict(linestyle='-',linewidth=1.0, color='black'),\n",
    "                             capprops = dict(linestyle='-',linewidth=2.0, color='red')\n",
    "                            )\n",
    "                             \n",
    "    boxplot.set_title('')\n",
    "    boxplot.set_xlabel('Classifiers')\n",
    "    boxplot.set_ylabel(metrics)\n",
    "    boxplot.tick_params(axis='y', which='minor', bottom=True)\n",
    "    boxplot.yaxis.grid(False)\n",
    "    boxplot.xaxis.grid(False)\n",
    "    \n",
    "    # Remove top and right border\n",
    "    boxplot.spines['top'].set_visible(False)\n",
    "    boxplot.spines['right'].set_visible(False)\n",
    "    \n",
    "    # Initialize minor ticks\n",
    "    boxplot.minorticks_on()\n",
    "\n",
    "    # Now minor ticks exist and are turned on for both axes\n",
    "    # Turn off x-axis minor ticks\n",
    "    boxplot.xaxis.set_tick_params(which='minor', bottom=False)\n",
    "    \n",
    "    # save the figure as JPEG\n",
    "    plotFile = './results/'+metrics+'-'+targetName+'_'+str(label)+'_'+str(folds)+'-foldCV.jpeg'\n",
    "    \n",
    "    boxplot.figure.savefig(plotFile,format='jpeg', dpi=300)\n",
    "    \n",
    "    print('* Saving plot:', plotFile)\n",
    "    \n",
    "    # clean each figure\n",
    "    boxplot.figure.clf()\n",
    "    \n",
    "    # return AUC scores for all classifiers as dataframe (each column a classifier)\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculations\n",
    "\n",
    "Set the dataset file as *sFile* and run the pipeline for different classifiers (no feature selection, no scaling):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for each subset file\n",
    "df_results = None # all results \n",
    "\n",
    "for OutVar in outVars:\n",
    "    # define a label for output files\n",
    "    targetName = 'sel' # for Pool use 'pool'\n",
    "    sFile = './ds/ds06_selected.txt' # for pool use './ds/ds06_pool.txt'\n",
    "    \n",
    "    # METRICS\n",
    "    metrics= 'roc_auc' # for accuracy use 'accuracy'\n",
    "\n",
    "    # get data from file\n",
    "    Xdata, Ydata, Features = getDataFromDataset(sFile,OutVar)\n",
    "\n",
    "    # Calculate class weights\n",
    "    class_weights = set_weights(Ydata)\n",
    "    print(\"Class weights = \", class_weights)\n",
    "        \n",
    "    # try different folds for each subset -> box plots\n",
    "    for folds in foldTypes:\n",
    "        \n",
    "        # calculate outer CV for different binary classifiers\n",
    "        df_fold = Pipeline_OuterCV(Xdata, Ydata, label = OutVar, class_weights = class_weights, folds = folds, seed = seed, metrics=metrics)\n",
    "        df_fold['Dataset'] = OutVar\n",
    "        df_fold['folds'] = folds\n",
    "        \n",
    "        # add each result to a summary dataframe\n",
    "        df_results = pd.concat([df_results,df_fold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box plots from results\n",
    "\n",
    "Load the results from file (if you dont want to run the previous calculations):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summaryFile = './results/accuracy-3-foldCV.csv'\n",
    "\n",
    "print('\\n-> Read summary results', summaryFile)\n",
    "df_results = pd.read_csv(summaryFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get list of classifiers from output file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierNames = list(df_results.columns)\n",
    "classifierNames.remove('Dataset')\n",
    "classifierNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "dd=pd.melt(df_results,id_vars=['Dataset'],value_vars=classifierNames,var_name='Classifiers')\n",
    "# replace value \n",
    "dd=dd.rename(columns = {'value':'ACC'})\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.clf()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.set(rc={'figure.figsize':(16,9)})\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.boxplot(x='Classifiers',y='ACC',data=dd,hue='Dataset',showmeans=True,\n",
    "                meanprops={\"marker\":\"o\",\n",
    "                           \"markerfacecolor\":\"white\", #white\n",
    "                           \"markeredgecolor\":\"black\",\n",
    "                           \"markersize\":\"8\"})\n",
    "#ax.set_ylim(.93, 1.0)\n",
    "plt.ylabel(\"ACC\", size=14)\n",
    "plt.xlabel(\"Machine Learning Classifiers\", size=14)\n",
    "\n",
    "# ax.set(ylim=(0.93, 1.1))\n",
    "ax.legend(loc='lower right')\n",
    "plt.savefig('./results/accuracy-3-foldCV_new.jpg', format='jpeg', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
